#!/usr/bin/env python3
"""
Daily Paper Trading Operations Script

Automates the complete daily trading workflow:
- Pre-market validation
- Trading session monitoring  
- End-of-day reporting and reconciliation

Usage:
    python ops/daily_paper_trading.py --mode preflight    # 08:00 CT
    python ops/daily_paper_trading.py --mode trading      # 08:30-15:00 CT
    python ops/daily_paper_trading.py --mode eod          # 15:10 CT
    python ops/daily_paper_trading.py --mode full         # Complete daily cycle
"""
import sys
import os
sys.path.append('.')

import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import time
import signal
import logging
import hashlib
import subprocess

from ops.paper_trading_guards import PaperTradingGuards
from ops.pre_market_dry_run import run_pre_market_dry_run
from ml.production_logging import setup_production_logging
from core.walk.xgb_model_loader import XGBModelLoader
from core.ml.feature_gate import prepare_X_for_xgb
from core.data.ingest import fetch_alpaca_bars, create_fallback_data
from core.ml.sector_residualizer import load_sector_map, sector_residualize
# from ml.paper_trading_reports import generate_daily_report, generate_weekly_report
# Note: Using mock reporting for now - will be implemented in full integration


class DailyPaperTradingOperations:
    """Automated daily paper trading operations."""
    
    def __init__(self):
        """Initialize daily operations."""
        # Load environment variables from .env file
        self._load_environment()
        
        self.logger = setup_production_logging(
            log_dir="logs",
            log_level="INFO"
        )
        self.logger.info("Daily paper trading operations initialized")
        
        self.trading_active = False
        self.daily_stats = {}
        self.alerts = []
        
        # Load production model
        self.model_loader = None
        self.sector_map = None
        self._load_production_model()
        self._load_sector_map()
        
        # Setup signal handlers for graceful shutdown
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def _load_environment(self):
        """Load environment variables from .env file."""
        from pathlib import Path
        
        env_file = Path('~/.config/paper-trading.env').expanduser()
        if env_file.exists():
            with open(env_file, 'r') as f:
                for line in f:
                    if '=' in line and not line.startswith('#'):
                        key, value = line.strip().split('=', 1)
                        os.environ[key] = value
    
    def _load_production_model(self):
        """Load the production XGBoost model."""
        try:
            model_path = "results/production/model.json"
            features_path = "results/production/features_whitelist.json"
            
            if not Path(model_path).exists():
                self.logger.warning(f"Production model not found at {model_path}, using mock trading")
                return
                
            if not Path(features_path).exists():
                self.logger.warning(f"Features whitelist not found at {features_path}, using mock trading")
                return
            
            self.model_loader = XGBModelLoader(model_path, features_path)
            
            self.logger.info("‚úÖ Production XGBoost model loaded successfully")
            self.logger.info(f"   Model: {model_path}")
            self.logger.info(f"   Features: {len(self.model_loader.features_whitelist)} features")
            
        except Exception as e:
            self.logger.error(f"Failed to load production model: {e}")
            self.logger.warning("Falling back to mock trading mode")
            self.model_loader = None
    
    def _load_sector_map(self):
        """Load sector classifications for residualization."""
        try:
            self.sector_map = load_sector_map()
            self.logger.info(f"‚úÖ Sector map loaded: {len(self.sector_map)} records")
        except Exception as e:
            self.logger.error(f"Failed to load sector map: {e}")
            self.sector_map = None
    
    def _generate_trading_signals(self, market_data: pd.DataFrame) -> Dict:
        """
        Generate trading signals using the production model with strict feature contract.
        
        Args:
            market_data: DataFrame with market data and features
            
        Returns:
            Dict with signals, positions, and metadata
        """
        if self.model_loader is None:
            self.logger.warning("MODEL DISABLED: No model loaded ‚Üí MOCK mode")
            return self._generate_mock_signals(market_data)
        
        try:
            # Apply sector residualization if sector map is available
            if self.sector_map is not None:
                # Get base features that need sector residualization (CSR features)
                csr_features = [f.replace('_sec_res', '') for f in self.model_loader.features_whitelist 
                              if f.endswith('_sec_res') and '_csr' in f]
                
                if csr_features:
                    market_data = sector_residualize(market_data, csr_features, self.sector_map)
                    self.logger.debug(f"Applied sector residualization to {len(csr_features)} CSR features")
            
            # Enforce feature contract - this will raise SystemExit if violated
            X = prepare_X_for_xgb(market_data, self.model_loader.features_whitelist)
            
            # Generate predictions using the model
            predictions = self.model_loader.predict(X)
            
            # Convert predictions to trading signals
            signals = self._predictions_to_signals(predictions, market_data)
            
            self.logger.info(f"‚úÖ USING MODEL ({len(self.model_loader.features_whitelist)}/{len(self.model_loader.features_whitelist)} features matched)")
            self.logger.info(f"Generated {len(signals)} trading signals using production model")
            
            return {
                'signals': signals,
                'predictions': predictions,
                'model_used': True,
                'feature_count': len(self.model_loader.features_whitelist),
                'timestamp': datetime.now().isoformat()
            }
            
        except SystemExit as e:
            # Feature contract violated - abort trading
            self.logger.critical(f"Feature contract violation: {e}")
            self.logger.critical("ABORTING TRADING - Feature contract not satisfied")
            raise  # Re-raise to stop the trading loop
            
        except Exception as e:
            self.logger.error(f"Error generating trading signals: {e}")
            self.logger.warning("MODEL DISABLED: Error in prediction ‚Üí MOCK mode")
            return self._generate_mock_signals(market_data)
    
    def _predictions_to_signals(self, predictions: np.ndarray, market_data: pd.DataFrame) -> Dict:
        """Convert model predictions to trading signals."""
        # Simple long-short strategy based on predictions
        # Top 20% long, bottom 20% short
        n_assets = len(predictions)
        n_long = max(1, int(n_assets * 0.2))
        n_short = max(1, int(n_assets * 0.2))
        
        # Rank predictions
        ranks = np.argsort(predictions)[::-1]  # Descending order
        
        signals = {}
        for i, rank in enumerate(ranks):
            symbol = market_data.index[rank]
            if i < n_long:
                signals[symbol] = 1.0 / n_long  # Equal weight long
            elif i >= n_assets - n_short:
                signals[symbol] = -1.0 / n_short  # Equal weight short
            else:
                signals[symbol] = 0.0  # Neutral
        
        return signals
    
    def _generate_mock_signals(self, market_data: pd.DataFrame) -> Dict:
        """Generate mock trading signals for testing."""
        np.random.seed(42)
        n_assets = len(market_data)
        
        # Random long-short signals
        signals = {}
        for symbol in market_data.index:
            signal = np.random.choice([-0.1, 0.0, 0.1], p=[0.2, 0.6, 0.2])
            signals[symbol] = signal
        
        return {
            'signals': signals,
            'predictions': np.random.randn(n_assets),
            'model_used': False,
            'feature_count': 0,
            'timestamp': datetime.now().isoformat()
        }
    
    def _fetch_real_market_data(self) -> pd.DataFrame:
        """Fetch real market data from Alpaca API."""
        try:
            # Use a subset of symbols for real-time trading
            symbols = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'NFLX', 'AMD', 'INTC']
            
            # Fetch latest prices from Alpaca
            df = fetch_alpaca_bars(symbols, timeframe="5Min", lookback_minutes=60)
            
            if df.empty:
                self.logger.warning("No data from Alpaca, using fallback")
                return self._generate_fallback_data(symbols)
            
            # Apply basic feature engineering (in production, this would be more sophisticated)
            df = self._engineer_features(df)
            
            self.logger.info(f"‚úÖ Fetched real market data: {len(df)} records for {df['symbol'].nunique()} symbols")
            return df
            
        except Exception as e:
            self.logger.error(f"Error fetching real market data: {e}")
            self.logger.warning("Falling back to mock data")
            return self._generate_fallback_data(['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA'])
    
    def _generate_fallback_data(self, symbols: List[str]) -> pd.DataFrame:
        """Generate fallback mock data when Alpaca is unavailable."""
        self.logger.warning("Using fallback mock data - Alpaca unavailable")
        
        data = []
        base_time = datetime.now()
        
        for symbol in symbols:
            # Generate realistic mock data
            base_price = 100 + hash(symbol) % 200  # Consistent base price per symbol
            price_change = np.random.normal(0, 0.02)  # 2% daily volatility
            
            close = base_price * (1 + price_change)
            high = close * (1 + abs(np.random.normal(0, 0.01)))
            low = close * (1 - abs(np.random.normal(0, 0.01)))
            open_price = close * (1 + np.random.normal(0, 0.005))
            
            data.append({
                'date': base_time,
                'symbol': symbol,
                'open': open_price,
                'high': high,
                'low': low,
                'close': close,
                'volume': int(np.random.uniform(100000, 1000000))
            })
        
        df = pd.DataFrame(data)
        df = self._engineer_features(df)
        return df
    
    def _engineer_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Apply comprehensive feature engineering to match the exact features used in training.
        This generates all the features needed for cross-sectional rank (csr) and z-score (csz) transformations.
        """
        # Ensure we have the required columns
        df = df.copy()
        df['close'] = df['close'].astype(float)
        df['volume'] = df['volume'].astype(float)
        
        # Sort by date and symbol for consistent processing
        df = df.sort_values(['date', 'symbol']).reset_index(drop=True)
        
        # Calculate features for each symbol individually to avoid index issues
        feature_dfs = []
        
        for symbol in df['symbol'].unique():
            symbol_df = df[df['symbol'] == symbol].copy().reset_index(drop=True)
            
            # Basic price features
            symbol_df['price_change'] = symbol_df['close'].pct_change().fillna(0)
            
            # Volatility features (using price changes)
            symbol_df['vol_5'] = symbol_df['price_change'].rolling(5).std().fillna(0)
            symbol_df['vol_20'] = symbol_df['price_change'].rolling(20).std().fillna(0)
            
            # Volume features
            symbol_df['volume_ratio'] = symbol_df['volume'] / symbol_df['volume'].rolling(20).mean().fillna(symbol_df['volume'])
            
            # Momentum features
            symbol_df['momentum_5'] = symbol_df['close'].pct_change(5).fillna(0)
            symbol_df['momentum_10'] = symbol_df['close'].pct_change(10).fillna(0)
            symbol_df['momentum_20'] = symbol_df['close'].pct_change(20).fillna(0)
            symbol_df['momentum_5_20'] = symbol_df['momentum_5'] - symbol_df['momentum_20']
            
            # Volatility features
            symbol_df['vol_ratio'] = symbol_df['vol_5'] / (symbol_df['vol_20'] + 1e-8)
            symbol_df['ret_vol_ratio'] = symbol_df['price_change'] / (symbol_df['vol_5'] + 1e-8)
            
            # Sharpe ratios
            symbol_df['sharpe_5'] = symbol_df['momentum_5'] / (symbol_df['vol_5'] + 1e-8)
            symbol_df['sharpe_20'] = symbol_df['momentum_20'] / (symbol_df['vol_20'] + 1e-8)
            
            # Volume acceleration
            symbol_df['volume_accel'] = symbol_df['volume'].pct_change().fillna(0)
            
            # Volume position
            symbol_df['volume_position_20'] = symbol_df['volume'] / (symbol_df['volume'].rolling(20).max().fillna(symbol_df['volume']) + 1e-8)
            
            # Liquidity proxy
            symbol_df['liquidity_proxy'] = symbol_df['volume'] * symbol_df['close']
            
            # Moving averages
            symbol_df['ma_fast'] = symbol_df['close'].rolling(10).mean().fillna(symbol_df['close'])
            symbol_df['ma_slow'] = symbol_df['close'].rolling(20).mean().fillna(symbol_df['close'])
            symbol_df['ma_ratio'] = symbol_df['ma_fast'] / (symbol_df['ma_slow'] + 1e-8)
            
            # Breakout signal
            symbol_df['breakout_signal'] = (symbol_df['close'] > symbol_df['ma_slow']).astype(int)
            
            # Bollinger Bands
            symbol_df['bb_upper'] = symbol_df['ma_slow'] + 2 * symbol_df['vol_20']
            symbol_df['bb_lower'] = symbol_df['ma_slow'] - 2 * symbol_df['vol_20']
            symbol_df['bb_width'] = (symbol_df['bb_upper'] - symbol_df['bb_lower']) / (symbol_df['ma_slow'] + 1e-8)
            symbol_df['bb_position'] = (symbol_df['close'] - symbol_df['bb_lower']) / (symbol_df['bb_upper'] - symbol_df['bb_lower'] + 1e-8)
            
            # RSI calculation
            delta = symbol_df['close'].diff().fillna(0)
            gain = delta.where(delta > 0, 0)
            loss = -delta.where(delta < 0, 0)
            avg_gain = gain.rolling(14).mean().fillna(0)
            avg_loss = loss.rolling(14).mean().fillna(0)
            rs = avg_gain / (avg_loss + 1e-8)
            symbol_df['rsi_14'] = 100 - (100 / (1 + rs))
            
            # Price-MA ratio
            symbol_df['price_ma_ratio'] = symbol_df['close'] / (symbol_df['ma_slow'] + 1e-8)
            
            # Mean reversion
            symbol_df['mean_reversion'] = (symbol_df['close'] - symbol_df['ma_slow']) / (symbol_df['vol_20'] + 1e-8)
            
            # Volatility regime (cross-sectional, will be calculated after combining)
            symbol_df['vol_regime_high'] = 0  # Placeholder
            symbol_df['vol_regime_low'] = 0   # Placeholder
            
            feature_dfs.append(symbol_df)
        
        # Combine all symbol data
        df = pd.concat(feature_dfs, ignore_index=True)
        
        # Calculate cross-sectional volatility regime features
        vol_median = df['vol_20'].median()
        df['vol_regime_high'] = (df['vol_20'] > vol_median * 1.5).astype(int)
        df['vol_regime_low'] = (df['vol_20'] < vol_median * 0.5).astype(int)
        
        # Fill any remaining NaN values and handle infinities
        df = df.fillna(0)
        df = df.replace([float('inf'), float('-inf')], 0)
        
        # Apply cross-sectional transformations
        df = self._apply_cross_sectional_transforms(df)
        
        return df
    
    def _apply_cross_sectional_transforms(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Apply cross-sectional rank (csr) and z-score (csz) transformations.
        """
        # Base features for cross-sectional transformation
        base_features = [
            'close', 'volume', 'vol_5', 'vol_20', 'volume_ratio', 'vol_ratio', 'ret_vol_ratio',
            'momentum_5', 'momentum_10', 'momentum_20', 'momentum_5_20',
            'sharpe_5', 'sharpe_20', 'volume_accel', 'vol_regime_high', 'vol_regime_low',
            'volume_position_20', 'liquidity_proxy', 'breakout_signal'
        ]
        
        # Apply cross-sectional rank (csr) transformation
        for feature in base_features:
            if feature in df.columns:
                # Cross-sectional rank (0-1)
                df[f'{feature}_csr'] = df.groupby('date')[feature].rank(pct=True)
        
        # Apply cross-sectional z-score (csz) transformation  
        csz_features = [
            'bb_upper', 'bb_lower', 'bb_width', 'bb_position',
            'ma_fast', 'ma_slow', 'ma_ratio', 'rsi_14', 'price_ma_ratio', 'mean_reversion'
        ]
        
        for feature in csz_features:
            if feature in df.columns:
                # Cross-sectional z-score
                mean_val = df.groupby('date')[feature].transform('mean')
                std_val = df.groupby('date')[feature].transform('std')
                df[f'{feature}_csz'] = (df[feature] - mean_val) / (std_val + 1e-8)
        
        # Final cleanup of any remaining NaN/Inf values
        df = df.fillna(0)
        df = df.replace([float('inf'), float('-inf')], 0)
        
        return df
    
    def _calculate_signal_entropy(self, signal_values: List[float]) -> float:
        """Calculate entropy of signal distribution."""
        if not signal_values:
            return 0.0
        
        # Convert to numpy array and remove zeros
        signals = np.array(signal_values)
        signals = signals[signals != 0]
        
        if len(signals) == 0:
            return 0.0
        
        # Normalize to probabilities
        abs_signals = np.abs(signals)
        total = np.sum(abs_signals)
        
        if total == 0:
            return 0.0
        
        probs = abs_signals / total
        
        # Calculate entropy
        entropy = -np.sum(probs * np.log(probs + 1e-10))
        
        return entropy
    
    def _signal_handler(self, signum, frame):
        """Handle shutdown signals gracefully."""
        self.logger.warning(f"Received signal {signum}, initiating graceful shutdown...")
        self.trading_active = False
        self._emergency_halt("Signal received")
    
    def _emergency_halt(self, reason: str):
        """Emergency halt with immediate position flattening."""
        self.logger.critical(f"EMERGENCY HALT: {reason}")
        
        try:
            # In real implementation, would flatten all positions
            halt_record = {
                'timestamp': datetime.now().isoformat(),
                'reason': reason,
                'action': 'emergency_halt',
                'positions_before_halt': self.daily_stats.get('current_positions', {}),
                'status': 'executed'
            }
            
            # Save halt record
            halt_dir = Path("results/paper/emergency_halts")
            halt_dir.mkdir(parents=True, exist_ok=True)
            
            halt_file = halt_dir / f"halt_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(halt_file, 'w') as f:
                json.dump(halt_record, f, indent=2)
            
            self.logger.critical(f"Emergency halt executed, record saved: {halt_file}")
            
            # Send alert
            self._send_alert("CRITICAL", f"Emergency halt executed: {reason}")
            
        except Exception as e:
            self.logger.critical(f"Failed to execute emergency halt: {e}")
    
    def _send_alert(self, level: str, message: str):
        """Send alert notification."""
        alert = {
            'timestamp': datetime.now().isoformat(),
            'level': level,
            'message': message
        }
        
        self.alerts.append(alert)
        
        # Log the alert
        if level == "CRITICAL":
            self.logger.critical(f"ALERT: {message}")
        elif level == "WARNING":
            self.logger.warning(f"ALERT: {message}")
        else:
            self.logger.info(f"ALERT: {message}")
        
        # In production, would send to notification service (Slack, email, etc.)
        print(f"üö® {level}: {message}")
    
    def run_preflight_checks(self) -> bool:
        """
        Run pre-market preflight checks (08:00 CT).
        
        Returns:
            True if all checks pass
        """
        self.logger.info("Starting preflight checks...")
        print("üåÖ PRE-MARKET PREFLIGHT CHECKS")
        print("="*50)
        
        all_passed = True
        
        # 1. Paper trading guards
        print("\nüîí Step 1: Paper trading environment validation...")
        try:
            guards = PaperTradingGuards()
            guard_result = guards.run_comprehensive_validation()
            
            if guard_result['validation_passed']:
                print("‚úÖ Paper trading environment validated")
            else:
                print("‚ùå Paper trading environment validation failed")
                for error in guard_result['errors']:
                    self.logger.error(f"Guard error: {error}")
                all_passed = False
                
        except Exception as e:
            print(f"‚ùå Guard validation failed: {e}")
            self.logger.error(f"Guard validation exception: {e}")
            all_passed = False
        
        # 2. Data freshness check
        print("\nüìä Step 2: Data freshness validation...")
        try:
            # Check if we have recent data (in production, check actual data timestamps)
            current_time = datetime.now()
            cutoff_time = current_time - timedelta(hours=24)
            
            # Mock data freshness check
            data_fresh = True  # Would check actual data files
            
            if data_fresh:
                print("‚úÖ Data freshness validated")
            else:
                print("‚ùå Stale data detected")
                self._send_alert("WARNING", "Stale data detected")
                all_passed = False
                
        except Exception as e:
            print(f"‚ùå Data freshness check failed: {e}")
            self.logger.error(f"Data freshness exception: {e}")
            all_passed = False
        
        # 3. Feature whitelist integrity
        print("\nüîê Step 3: Feature whitelist integrity...")
        try:
            whitelist_path = "results/production/features_whitelist.json"
            hash_path = "results/production/features_whitelist.json.hash"
            
            if Path(whitelist_path).exists() and Path(hash_path).exists():
                with open(whitelist_path, 'r') as f:
                    whitelist = json.load(f)
                
                content = json.dumps(sorted(whitelist), sort_keys=True)
                current_hash = hashlib.sha256(content.encode()).hexdigest()
                
                with open(hash_path, 'r') as f:
                    expected_hash = f.read().strip()
                
                if current_hash == expected_hash:
                    print(f"‚úÖ Feature whitelist integrity verified ({len(whitelist)} features)")
                else:
                    print("‚ùå Feature whitelist integrity check failed")
                    self._send_alert("CRITICAL", "Feature whitelist tampering detected")
                    all_passed = False
            else:
                print("‚ö†Ô∏è Feature whitelist files missing")
                self._send_alert("WARNING", "Feature whitelist files missing")
                
        except Exception as e:
            print(f"‚ùå Feature whitelist check failed: {e}")
            self.logger.error(f"Whitelist check exception: {e}")
            all_passed = False
        
        # 4. Trading calendar validation
        print("\nüìÖ Step 4: Trading calendar validation...")
        try:
            today = datetime.now().date()
            
            # Simple business day check (in production, use proper market calendar)
            is_business_day = today.weekday() < 5
            
            if is_business_day:
                print(f"‚úÖ Trading day confirmed: {today}")
            else:
                print(f"‚ÑπÔ∏è Non-trading day: {today}")
                # Not a failure, just informational
                
        except Exception as e:
            print(f"‚ùå Calendar validation failed: {e}")
            self.logger.error(f"Calendar validation exception: {e}")
        
        # 5. Pre-market dry run
        print("\nüß™ Step 5: Pre-market dry run...")
        try:
            # Use enhanced dry-run with proper date handling
            import subprocess
            result = subprocess.run(['python', 'ops/enhanced_dry_run.py'], 
                                  capture_output=True, text=True, cwd=os.getcwd())
            if result.returncode == 0:
                dry_run_result = {'overall_status': 'pass'}
                print("‚úÖ Enhanced dry-run completed successfully")
            else:
                dry_run_result = {'overall_status': 'fail'}
                print("‚ùå Enhanced dry-run failed")
            
            if dry_run_result['overall_status'] == 'pass':
                print("‚úÖ Pre-market dry run passed")
            else:
                print("‚ö†Ô∏è Pre-market dry run issues detected")
                self._send_alert("WARNING", "Pre-market dry run detected issues")
                # Don't fail preflight for dry run warnings
                
        except Exception as e:
            print(f"‚ö†Ô∏è Pre-market dry run failed: {e}")
            self.logger.warning(f"Dry run exception: {e}")
        
        # Summary
        print(f"\nüìã PREFLIGHT SUMMARY:")
        if all_passed:
            print("‚úÖ ALL PREFLIGHT CHECKS PASSED - READY FOR TRADING")
            self.logger.info("Preflight checks completed successfully")
        else:
            print("‚ùå PREFLIGHT ISSUES DETECTED - REVIEW BEFORE TRADING")
            self.logger.error("Preflight checks failed")
            self._send_alert("CRITICAL", "Preflight checks failed")
        
        return all_passed
    
    def run_trading_session(self) -> Dict:
        """
        Run trading session monitoring (08:30-15:00 CT).
        
        Returns:
            Dict with trading session results
        """
        self.logger.info("Starting trading session...")
        print("üìà TRADING SESSION ACTIVE")
        print("="*30)
        
        self.trading_active = True
        session_stats = {
            'start_time': datetime.now().isoformat(),
            'bars_processed': 0,
            'alerts_triggered': 0,
            'positions_taken': 0,
            'adv_breaches': 0,
            'emergency_halts': 0
        }
        
        # Real trading loop with model integration
        try:
            bar_count = 0
            consecutive_low_entropy = 0
            
            print("üîÑ Starting trading loop...")
            if self.model_loader:
                print("   Using production XGBoost model for signal generation")
            else:
                print("   Using mock signals (no model loaded)")
            print("   Monitoring: entropy, PnL, slippage, ADV breaches")
            
            # Simulate trading session (normally runs for market hours)
            max_bars = 50  # Simulate ~6.5 hour session with frequent checks
            
            while self.trading_active and bar_count < max_bars:
                bar_count += 1
                
                # Fetch real market data from Alpaca API
                market_data = self._fetch_real_market_data()
                
                # Generate trading signals using the model
                signal_result = self._generate_trading_signals(market_data)
                signals = signal_result['signals']
                model_used = signal_result['model_used']
                
                # Calculate entropy from signal distribution
                signal_values = list(signals.values())
                action_entropy = self._calculate_signal_entropy(signal_values)
                
                # Mock PnL calculation (in production, would use real portfolio PnL)
                daily_pnl_pct = np.random.uniform(-0.01, 0.01)  # -1% to +1%
                
                # Mock slippage tracking
                expected_slippage = 0.0006  # 6 bps
                realized_slippage = expected_slippage * np.random.uniform(0.8, 1.4)
                slippage_deviation = abs(realized_slippage - expected_slippage) / expected_slippage
                
                # Check kill conditions
                kill_triggered = False
                
                # 1. Entropy floor check
                if action_entropy < 0.75:
                    consecutive_low_entropy += 1
                    if consecutive_low_entropy >= 10:
                        self._send_alert("CRITICAL", f"Low entropy for {consecutive_low_entropy} bars: {action_entropy:.3f}")
                        kill_triggered = True
                else:
                    consecutive_low_entropy = 0
                
                # 2. Daily loss limit
                if daily_pnl_pct <= -0.02:  # -2%
                    self._send_alert("CRITICAL", f"Daily loss limit breached: {daily_pnl_pct:.2%}")
                    kill_triggered = True
                
                # 3. Slippage deviation
                if slippage_deviation > 3.0:  # 3 sigma (simplified)
                    self._send_alert("WARNING", f"High slippage deviation: {slippage_deviation:.1f}x expected")
                    session_stats['alerts_triggered'] += 1
                
                # Emergency halt if kill condition triggered
                if kill_triggered:
                    self._emergency_halt("Kill condition triggered")
                    session_stats['emergency_halts'] += 1
                    break
                
                # Progress update every 10 bars
                if bar_count % 10 == 0:
                    model_status = "MODEL" if model_used else "MOCK"
                    n_signals = len([s for s in signal_values if s != 0])
                    feature_count = signal_result.get('feature_count', 0)
                    print(f"   Bar {bar_count}: {model_status} ({feature_count}/45) entropy={action_entropy:.3f}, signals={n_signals}, PnL={daily_pnl_pct:.2%}, slippage={realized_slippage*10000:.1f}bps")
                
                session_stats['bars_processed'] = bar_count
                
                # Simulate processing time
                time.sleep(0.1)
            
            session_stats['end_time'] = datetime.now().isoformat()
            
            if self.trading_active:
                print(f"‚úÖ Trading session completed: {bar_count} bars processed")
                self.logger.info(f"Trading session completed successfully: {bar_count} bars")
            else:
                print(f"‚ö†Ô∏è Trading session halted early: {bar_count} bars processed")
                self.logger.warning(f"Trading session halted: {bar_count} bars")
            
        except Exception as e:
            print(f"‚ùå Trading session error: {e}")
            self.logger.error(f"Trading session exception: {e}")
            self._emergency_halt(f"Trading session exception: {e}")
            session_stats['emergency_halts'] += 1
        
        finally:
            self.trading_active = False
        
        return session_stats
    
    def run_eod_operations(self) -> Dict:
        """
        Run end-of-day operations (15:10 CT).
        
        Returns:
            Dict with EOD results
        """
        self.logger.info("Starting end-of-day operations...")
        print("üåÜ END-OF-DAY OPERATIONS")
        print("="*30)
        
        eod_results = {
            'timestamp': datetime.now().isoformat(),
            'reports_generated': [],
            'reconciliation_status': 'pending',
            'alerts_summary': len(self.alerts)
        }
        
        try:
            # 1. Generate daily report
            print("\nüìä Step 1: Generating daily report...")
            
            # Mock trading data for report
            today = datetime.now().strftime('%Y-%m-%d')
            mock_trading_data = {
                'date': today,
                'ic': np.random.uniform(0.010, 0.025),
                'sharpe_net': np.random.uniform(0.25, 0.40),
                'turnover': np.random.uniform(1.5, 2.2),
                'decile_spread': np.random.uniform(0.008, 0.015),
                'factor_r2': np.random.uniform(0.15, 0.35),
                'realized_slippage_bps': np.random.uniform(5.0, 8.0),
                'expected_slippage_bps': 6.0,
                'blocked_order_pct': np.random.uniform(0.0, 5.0),
                'guard_breaches': 0,
                'positions_count': np.random.randint(15, 25)
            }
            
            # Mock daily report for now
            daily_report = {
                'date': today,
                'status': 'mock_validation',
                'metrics': mock_trading_data
            }
            
            # Save daily report
            reports_dir = Path("results/paper/reports")
            reports_dir.mkdir(parents=True, exist_ok=True)
            
            daily_report_file = reports_dir / f"daily_{today}.json"
            with open(daily_report_file, 'w') as f:
                json.dump(daily_report, f, indent=2)
            
            print(f"‚úÖ Daily report saved: {daily_report_file}")
            eod_results['reports_generated'].append(str(daily_report_file))
            
            # 2. Check if weekly report needed (Friday)
            if datetime.now().weekday() == 4:  # Friday
                print("\nüìà Step 2: Generating weekly report...")
                
                # Mock weekly data
                weekly_data = [mock_trading_data for _ in range(5)]  # 5 trading days
                # Mock weekly report for now  
                weekly_report = {
                    'week_ending': today,
                    'status': 'mock_validation',
                    'daily_data': weekly_data
                }
                
                weekly_report_file = reports_dir / f"weekly_{today}.json"
                with open(weekly_report_file, 'w') as f:
                    json.dump(weekly_report, f, indent=2)
                
                print(f"‚úÖ Weekly report saved: {weekly_report_file}")
                eod_results['reports_generated'].append(str(weekly_report_file))
            
            # 3. Position reconciliation
            print("\nüîç Step 3: Position reconciliation...")
            
            # Mock reconciliation (in production, compare with broker positions)
            reconciliation_passed = True  # Mock result
            
            if reconciliation_passed:
                print("‚úÖ Position reconciliation passed")
                eod_results['reconciliation_status'] = 'passed'
            else:
                print("‚ùå Position reconciliation failed")
                eod_results['reconciliation_status'] = 'failed'
                self._send_alert("CRITICAL", "Position reconciliation failed")
            
            # 4. Alerts summary
            print(f"\nüö® Step 4: Alerts summary...")
            print(f"   Total alerts today: {len(self.alerts)}")
            
            if self.alerts:
                alert_file = reports_dir / f"alerts_{today}.json"
                with open(alert_file, 'w') as f:
                    json.dump(self.alerts, f, indent=2)
                print(f"   Alerts saved: {alert_file}")
            
            print(f"\n‚úÖ End-of-day operations completed")
            
        except Exception as e:
            print(f"‚ùå End-of-day operations failed: {e}")
            self.logger.error(f"EOD operations exception: {e}")
            self._send_alert("CRITICAL", f"EOD operations failed: {e}")
        
        return eod_results
    
    def run_full_day_cycle(self) -> Dict:
        """
        Run complete daily cycle.
        
        Returns:
            Dict with full day results
        """
        print("üîÑ RUNNING FULL DAILY PAPER TRADING CYCLE")
        print("="*60)
        
        full_day_results = {
            'date': datetime.now().strftime('%Y-%m-%d'),
            'start_time': datetime.now().isoformat(),
            'preflight': None,
            'trading_session': None,
            'eod': None,
            'overall_status': 'pending'
        }
        
        try:
            # Step 1: Preflight checks
            print("\n" + "="*20 + " PREFLIGHT " + "="*20)
            preflight_passed = self.run_preflight_checks()
            full_day_results['preflight'] = {'passed': preflight_passed}
            
            if not preflight_passed:
                print("\n‚ùå ABORTING: Preflight checks failed")
                full_day_results['overall_status'] = 'aborted'
                return full_day_results
            
            # Step 2: Trading session
            print("\n" + "="*20 + " TRADING " + "="*20)
            trading_results = self.run_trading_session()
            full_day_results['trading_session'] = trading_results
            
            # Step 3: End-of-day operations
            print("\n" + "="*22 + " EOD " + "="*22)
            eod_results = self.run_eod_operations()
            full_day_results['eod'] = eod_results
            
            # Overall status
            if (preflight_passed and 
                trading_results.get('emergency_halts', 0) == 0 and
                eod_results.get('reconciliation_status') == 'passed'):
                full_day_results['overall_status'] = 'success'
            else:
                full_day_results['overall_status'] = 'issues'
            
            print(f"\nüéØ DAILY CYCLE COMPLETE: {full_day_results['overall_status'].upper()}")
            
        except Exception as e:
            print(f"‚ùå Daily cycle failed: {e}")
            self.logger.critical(f"Daily cycle exception: {e}")
            full_day_results['overall_status'] = 'failed'
        
        finally:
            full_day_results['end_time'] = datetime.now().isoformat()
            
            # Save daily cycle results
            results_dir = Path("results/paper/daily_cycles")
            results_dir.mkdir(parents=True, exist_ok=True)
            
            results_file = results_dir / f"cycle_{full_day_results['date']}.json"
            with open(results_file, 'w') as f:
                json.dump(full_day_results, f, indent=2)
            
            print(f"üìÑ Daily cycle results saved: {results_file}")
        
        return full_day_results


def main():
    """CLI entry point."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Daily Paper Trading Operations")
    parser.add_argument('--mode', choices=['preflight', 'trading', 'eod', 'full'],
                       default='full', help="Operation mode")
    
    args = parser.parse_args()
    
    # Initialize operations
    ops = DailyPaperTradingOperations()
    
    try:
        if args.mode == 'preflight':
            success = ops.run_preflight_checks()
            sys.exit(0 if success else 1)
            
        elif args.mode == 'trading':
            results = ops.run_trading_session()
            sys.exit(0 if results.get('emergency_halts', 0) == 0 else 1)
            
        elif args.mode == 'eod':
            results = ops.run_eod_operations()
            sys.exit(0 if results.get('reconciliation_status') == 'passed' else 1)
            
        elif args.mode == 'full':
            results = ops.run_full_day_cycle()
            sys.exit(0 if results.get('overall_status') == 'success' else 1)
            
    except KeyboardInterrupt:
        print("\nüõë Operation interrupted by user")
        ops.logger.warning("Operation interrupted by user")
        sys.exit(130)
    
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {e}")
        ops.logger.critical(f"Unexpected exception: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
