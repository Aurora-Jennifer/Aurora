#!/usr/bin/env python3
"""
Aurora Repository Indexer
Auto-generates README.md files for directories and creates module maps.
"""

import re
import sys
from pathlib import Path


class RepoIndexer:
    def __init__(self, root_dir: str = "."):
        self.root_dir = Path(root_dir)
        self.excluded_dirs = {
            ".venv",
            "venv",
            "__pycache__",
            ".pytest_cache",
            ".ruff_cache",
            ".perf",
            ".hypothesis",
            ".git",
        }
        self.excluded_files = {".DS_Store", "Thumbs.db"}

    def scan_directory(self, dir_path: Path) -> dict[str, list[dict]]:
        """Scan directory for Python files and generate documentation."""
        files = []

        if not dir_path.exists() or not dir_path.is_dir():
            return files

        for item in dir_path.iterdir():
            if item.name in self.excluded_dirs or item.name.startswith("."):
                continue

            if item.is_file() and item.suffix == ".py":
                file_info = self.analyze_python_file(item)
                if file_info:
                    files.append(file_info)
            elif item.is_dir() and item.name not in self.excluded_dirs:
                # Recursively scan subdirectories
                sub_files = self.scan_directory(item)
                files.extend(sub_files)

        return files

    def analyze_python_file(self, file_path: Path) -> dict:
        """Analyze a Python file and extract documentation."""
        try:
            with open(file_path, encoding="utf-8") as f:
                content = f.read()

            # Extract first docstring or comment
            docstring = self.extract_docstring(content)
            if not docstring:
                docstring = self.extract_first_comment(content)

            # Get relative path from root
            rel_path = file_path.relative_to(self.root_dir)

            return {
                "path": str(rel_path),
                "name": file_path.stem,
                "description": docstring or "No description available",
                "size": file_path.stat().st_size,
                "lines": len(content.splitlines()),
            }
        except Exception as e:
            print(f"Error analyzing {file_path}: {e}")
            return None

    def extract_docstring(self, content: str) -> str:
        """Extract the first docstring from Python code."""
        # Look for module docstring
        docstring_pattern = r'"""(.*?)"""'
        match = re.search(docstring_pattern, content, re.DOTALL)
        if match:
            doc = match.group(1).strip()
            return doc.split("\n")[0] if doc else None
        return None

    def extract_first_comment(self, content: str) -> str:
        """Extract the first meaningful comment from Python code."""
        lines = content.splitlines()
        for line in lines:
            line = line.strip()
            if line.startswith("#") and len(line) > 1:
                comment = line[1:].strip()
                if comment and not comment.startswith("!"):
                    return comment
        return None

    def generate_readme(self, dir_path: Path, files: list[dict]) -> str:
        """Generate README.md content for a directory."""
        if not files:
            return "# Empty Directory\n\nThis directory contains no Python files.\n"
        # Sort files by name
        files.sort(key=lambda x: x["name"])

        readme = f"# {dir_path.name.title()} Directory\n\n"
        readme += f"This directory contains {len(files)} Python file(s).\n\n"
        readme += "## Files\n\n"
        readme += "| File | Description | Lines |\n"
        readme += "|------|-------------|-------|\n"
        for file_info in files:
            name = file_info["name"]
            description = (
                file_info["description"][:60] + "..."
                if len(file_info["description"]) > 60
                else file_info["description"]
            )
            lines = file_info["lines"]
            readme += f"| `{name}.py` | {description} | {lines} |\n"
        readme += "\n## Usage\n\n"
        readme += "Import modules from this directory:\n\n"
        readme += "```python\n"
        for file_info in files:
            module_name = file_info["name"]
            readme += f"from {dir_path.name} import {module_name}\n"
        readme += "```\n\n"
        readme += "---\n\n"
        readme += "*Auto-generated by Aurora Repository Indexer*\n"
        return readme

    def generate_module_map(self, all_files: list[dict]) -> str:
        """Generate a comprehensive module map."""
        # Group files by directory
        dirs = {}
        for file_info in all_files:
            dir_name = Path(file_info["path"]).parent
            if dir_name not in dirs:
                dirs[dir_name] = []
            dirs[dir_name].append(file_info)
        # Sort directories
        sorted_dirs = sorted(dirs.keys())
        module_map = "# Aurora Module Map\n\n"
        module_map += "Comprehensive map of all Python modules in the Aurora trading system.\n\n"
        module_map += f"**Total Files:** {len(all_files)}\n"
        module_map += f"**Total Directories:** {len(sorted_dirs)}\n\n"
        for dir_name in sorted_dirs:
            dir_display = "Root" if dir_name == Path(".") else str(dir_name)
            module_map += f"## {dir_display}\n\n"
            files = dirs[dir_name]
            files.sort(key=lambda x: x["name"])
            for file_info in files:
                module_map += f"- **{file_info['name']}.py** ({file_info['lines']} lines)\n"
                module_map += f"  - {file_info['description']}\n"
                module_map += f"  - Path: `{file_info['path']}`\n\n"
        module_map += "---\n\n"
        module_map += "*Auto-generated by Aurora Repository Indexer*\n"
        return module_map

    def run(self):
        """Main execution method."""
        print("ðŸ” Aurora Repository Indexer")
        print("=" * 40)
        # Scan all Python files
        all_files = self.scan_directory(self.root_dir)
        print(f"Found {len(all_files)} Python files")
        # Generate module map
        module_map_content = self.generate_module_map(all_files)
        module_map_path = self.root_dir / "MODULE_MAP.md"
        with open(module_map_path, "w", encoding="utf-8") as f:
            f.write(module_map_content)
        print(f"âœ… Generated {module_map_path}")
        # Generate README files for directories with Python files
        dirs_with_files = {}
        for file_info in all_files:
            dir_name = Path(file_info["path"]).parent
            if dir_name not in dirs_with_files:
                dirs_with_files[dir_name] = []
            dirs_with_files[dir_name].append(file_info)
        readme_count = 0
        for dir_name, files in dirs_with_files.items():
            if dir_name == Path("."):
                continue  # Skip root directory
            dir_path = self.root_dir / dir_name
            readme_content = self.generate_readme(dir_path, files)
            readme_path = dir_path / "README.md"
            # Only write if README doesn't exist or is auto-generated
            if (
                not readme_path.exists()
                or "Auto-generated by Aurora Repository Indexer" in readme_path.read_text()
            ):
                with open(readme_path, "w", encoding="utf-8") as f:
                    f.write(readme_content)
                readme_count += 1
                print(f"âœ… Generated {readme_path}")
        print("\nðŸŽ‰ Indexing complete!")
        print(f"- Generated {readme_count} README files")
        print("- Updated MODULE_MAP.md")
        print(f"- Total files indexed: {len(all_files)}")


def main():
    """Command line interface."""
    root_dir = sys.argv[1] if len(sys.argv) > 1 else "."
    indexer = RepoIndexer(root_dir)
    indexer.run()


if __name__ == "__main__":
    main()
